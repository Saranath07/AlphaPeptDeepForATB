{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from peptdeep.pretrained_models import ModelManager\n",
    "\n",
    "model_mgr = ModelManager(mask_modloss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peptdeep.model.rt import IRT_PEPTIDE_DF\n",
    "IRT_PEPTIDE_DF['charge'] = 2\n",
    "IRT_PEPTIDE_DF['nce'] = 30.0\n",
    "IRT_PEPTIDE_DF['instrument'] = 'QE'\n",
    "trace_df = IRT_PEPTIDE_DF.query('nAA==12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.jit.trace to compile \n",
    "\n",
    "`torch.jit.script()` does not allow global variables, *args and **kwargs, so it does not work for huggingface transformers.\n",
    "\n",
    "But `torch.jit.trace()` works well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace RT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model_mgr.rt_model._get_features_from_batch_df(\n",
    "    trace_df\n",
    ")\n",
    "model_mgr.rt_model.model.eval()\n",
    "traced_rt = torch.jit.trace(model_mgr.rt_model.model, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4009], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_rt(*model_mgr.rt_model._get_features_from_batch_df(\n",
    "    IRT_PEPTIDE_DF.query('nAA==10')\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace CCS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model_mgr.ccs_model._get_features_from_batch_df(\n",
    "    trace_df\n",
    ")\n",
    "model_mgr.ccs_model.model.eval()\n",
    "traced_ccs = torch.jit.trace(model_mgr.ccs_model.model, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([364.8280], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_ccs(*model_mgr.ccs_model._get_features_from_batch_df(\n",
    "    IRT_PEPTIDE_DF.query('nAA==10')\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace MS2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zengwenfeng/Workspace/alphapeptdeep/peptdeep/model/building_block.py:422: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return x + self.pe[:,:x.size(1),:]\n"
     ]
    }
   ],
   "source": [
    "features = model_mgr.ms2_model._get_features_from_batch_df(\n",
    "    trace_df\n",
    ")\n",
    "model_mgr.ms2_model.model.eval()\n",
    "traced_ms2=torch.jit.trace(model_mgr.ms2_model.model, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_ms2(*model_mgr.ms2_model._get_features_from_batch_df(\n",
    "    IRT_PEPTIDE_DF.query('nAA==10')\n",
    ")).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save traced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.jit.save(traced_ms2, \"traced_ms2.pt\")\n",
    "# torch.jit.save(traced_rt, \"traced_rt.pt\")\n",
    "# torch.jit.save(traced_ccs, \"traced_ccs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traced_model = torch.jit.load(...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a3b27e141e49c996c9b863f8707e97aabd49c4a7e8445b9b783b34e4a21a9b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
